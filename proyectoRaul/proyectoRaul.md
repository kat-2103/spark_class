# An√°lisis de Viajes en Taxi de Nueva York üöñ NYC Yellow Taxi Trips

> Este proyecto analiza los datos hist√≥ricos de los viajes en taxi amarillo de la ciudad de Nueva York con el objetivo de identificar patrones horarios, optimizar recursos y tomar decisiones basadas en datos.

---

## üìå Descripci√≥n del Proyecto

Este proyecto realiza un **pipeline ETL completo** desde la ingesta de datos hasta la generaci√≥n de m√©tricas clave sobre los viajes en taxi. Los datos provienen de la TLC (Taxi and Limousine Commission), y se procesan utilizando **Apache Spark** en **Databricks Community Edition**, almacenando resultados en **Delta Lake** y exponiendo dashboards interactivos.

---

## üîß Tecnolog√≠as Utilizadas

- **Databricks Community Edition**
- **Apache Spark / PySpark**
- **Delta Lake**
- **Python (Pandas, PySpark SQL)**
- **SQL (para consultas en Databricks)**

---

## üó∫Ô∏è Pipeline ETL

### 1. üíæ Ingesta de Datos

- Se descargan archivos .parquet mensuales de los viajes en taxi desde 2020 hasta 2024.
- Se convierten de `.parquet` a `.csv` .
- Se almacenan en una ruta local dentro del workspace de Databricks.

### 2. üîÑ Transformaci√≥n

- Limpieza de valores nulos:
  - Imputaci√≥n de medias en columnas num√©ricas: `fare_amount`, `trip_distance`, etc.
  -  Los valores nulos en columnas num√©ricas pueden distorsionar los an√°lisis y modelos predictivos. Imputar (rellenar)     estos valores con la media de la columna ayuda a mantener la integridad de los datos sin introducir sesgos significativos.
- Conversi√≥n de fechas (`tpep_pickup_datetime`, `tpep_dropoff_datetime`) a formato `timestamp`.
  - Convertir las fechas a formato timestamp permite realizar operaciones de tiempo m√°s precisas y eficientes, como c√°lculos de duraci√≥n, filtrado por rangos de fechas y agrupaciones por hora, d√≠a, mes, etc.
- Eliminaci√≥n de columnas irrelevantes: `airport_fee`, `RatecodeID`, `store_and_fwd_flag`, etc.
  -  Algunas columnas pueden no ser relevantes para el an√°lisis o pueden contener datos redundantes. Eliminar estas columnas reduce el tama√±o del DataFrame y mejora la eficiencia del procesamiento.
- Filtrado de registros inv√°lidos: `passenger_count = 0`, `fare_amount <= 0`.
  - Los registros con valores inv√°lidos pueden sesgar los resultados del an√°lisis. Filtrar estos registros asegura que solo se analicen datos v√°lidos y significativos.
- Generaci√≥n de nuevas columnas:
  - Hora de recogida y destino (`hora_int_pickup`, `hora_int_dropoff`)
  - Extraer la hora de las fechas de recogida y destino permite analizar patrones horarios, como identificar las horas pico de demanda.

### 3. üìä Agregaci√≥n por hora

Se generan tres tablas Delta con las siguientes m√©tricas agrupadas por hora:

| Tabla | M√©tricas |
|-------|----------|
| `viajes_por_hora` | Distancia promedio, duraci√≥n promedio, tarifa base y total promedio |
| `pasajeros_df` | Total de pasajeros, cantidad de viajes, promedio de pasajeros por viaje |
| `ingresos_por_hora` | Ingresos totales, cantidad de viajes, ingreso promedio por viaje |
| `ingresos_por_franja` | Franja horaria, ingresos totales, cantidad de viajes, ingreso promedio por viaje |

Adem√°s, se categorizan las horas en franjas horarias:
- Ma√±ana (6-11)
- Mediod√≠a (12-14)
- Tarde (15-19)
- Noche (20-23)
- Madrugada (0-5)

### 4. üóÉ Almacenamiento

Los datos transformados se guardan como tablas Delta para permitir versionado, actualizaci√≥n incremental y mejor rendimiento en consultas posteriores.

```python
viajes_por_hora.write.format('delta').mode('overwrite').saveAsTable('workspace.default.viajes_por_hora')
```

### üìä Dashboards Interactivos

En Databricks, se crearon dashboards interactivos con visualizaciones clave:

- Promedio de tarifas por hora del d√≠a
- 
![image](https://github.com/user-attachments/assets/b4d4b4b5-d7d9-4909-a98a-32482b978ef2)

- Total de pasajeros por hora

  ![image](https://github.com/user-attachments/assets/e4ea880c-4304-43c4-ba82-eabb968f615b)

- Distancia media recorrida por hora

![image](https://github.com/user-attachments/assets/8b899b4c-9ac7-4c23-868c-c068dd89fce2)

- Ingresos totales por franja horaria

![image](https://github.com/user-attachments/assets/5b41b680-7fad-4627-a316-be6575ff2b82)


### ‚è± Automatizaci√≥n (Opcional)

El proceso puede ser automatizado usando Jobs en Databricks para ejecutar peri√≥dicamente el pipeline y actualizar los datos sin intervenci√≥n manual. Se crearon dos tareas distintas:

#### Tarea de Ingesta de Datos

- Esta tarea ejecuta el notebook de ingesta de datos, descargando y almacenando los archivos `.parquet` mensuales de los viajes en taxi.

#### Tarea de Transformaci√≥n ETL

- Esta tarea ejecuta el notebook de transformaci√≥n ETL, aplicando las limpiezas, transformaciones y agregaciones necesarias a los datos.

Ambas tareas est√°n configuradas con triggers para ejecutarse de manera peri√≥dica, asegurando que los datos se mantengan actualizados sin necesidad de intervenci√≥n manual.

---

## üß™ C√≥mo Ejecutar el Proyecto

1. Acceder a Databricks Community Edition: Databricks Community Edition
2. Crear un notebook en PySpark
3. Ejecutar el c√≥digo paso a paso:
   - Instalar dependencias (si es necesario): `%pip install pyspark`
   - Convertir `.parquet` a `.csv`
   - Leer los archivos con Spark
   - Aplicar limpieza, transformaci√≥n y agregaciones
   - Guardar en Delta Lake
   - Visualizar resultados
4. Crear Dashboards:
   - Usar bot√≥n + Add to Dashboard en cada gr√°fico
   - Crear un dashboard llamado NYC Taxi Dashboard

---

## üß† Insights Clave

- Las horas nocturnas son las horas en las que hay mas promedio de tarifa.
- La franja de tarde genera m√°s ingresos totales debido a que hay una mayor cantidad de viajes.
- Por la tarde es cuando mas cantidad de pasajeros hay concretamente a las 18:00.
- Cuando mas distancia promedio hay es en la madrugada.
---

## üë• Autores

- Raul Agras Basanta

---

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Consulta el archivo LICENSE para m√°s detalles.
