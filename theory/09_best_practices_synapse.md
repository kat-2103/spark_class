# 游늭 09 - Buenas Pr치cticas Trabajando en Azure Synapse Analytics

---

# 游 Objetivo

Adoptar buenas pr치cticas al usar Azure Synapse Analytics para:
- Optimizar el rendimiento.
- Evitar costes innecesarios.
- Trabajar de manera ordenada y profesional.

---

# 游늵 1. Control de Costes

- **Configura Auto-pause** en Spark Pools (pausar tras 15 minutos de inactividad).
- **Usa Autoscale** para ajustar el n칰mero de nodos seg칰n carga de trabajo.
- **Det칠n manualmente Spark Sessions** cuando termines (`Stop session` en Synapse Studio).
- **Revisa peri칩dicamente el coste en Azure Portal**.

> 游댲 **Regla de oro:** No dejes Spark Pools encendidos si no los est치s usando.

---

# 游늵 2. Organizaci칩n de Recursos

- **Nombre consistente para Spark Pools** (ej: `sparkpool-desarrollo`, `sparkpool-pruebas`).
- **Nombre claro para Notebooks**:
  - Prefijo de proyecto + descripci칩n breve (ej: `ETL_IngestionVentas`, `Transform_Clientes`).
- **Agrupa los Notebooks** en carpetas tem치ticas.
- **Versiona Notebooks**: guarda versiones importantes (puedes exportarlos `.ipynb` si quieres).

---

# 游늵 3. Mejores Pr치cticas en C칩digo PySpark

- **Usa nombres claros** de variables y columnas.
- **Divide el c칩digo en celdas peque침as**: facilita la lectura y la depuraci칩n.
- **Agrega celdas Markdown** explicando el objetivo de cada parte.
- **Evita `collect()` sobre grandes vol칰menes de datos**:
  - Traer muchos datos al driver puede saturar la memoria.
  - Prefiere usar `show()`, `take()`, `limit()`, etc.

---

# 游늵 4. Buenas pr치cticas de Sesiones

- **Adjunta el Notebook al Spark Pool adecuado**.
- **No abras m칰ltiples sesiones en paralelo** si no es necesario.
- **Planifica cargas de trabajo**: agrupa ejecuciones para aprovechar la sesi칩n activa.


---

# 游늵 5. Seguridad y Accesos

- Usa **roles y permisos** para controlar qui칠n puede leer/escribir datos.
- No compartas informaci칩n sensible en Notebooks.
- Configura accesos limitados a Data Lake si trabajas en equipo.


---

# 游늵 6. Uso del Almacenamiento

- Utiliza **Data Lake Storage Gen2** como repositorio central de archivos.
- Crea una **estructura de carpetas** l칩gica: `/landing`, `/raw`, `/curated`.
- Prefiere formatos eficientes:
  - **Parquet** sobre **CSV** o **JSON** (mejor compresi칩n y velocidad).


---

# 游닄 Resumen de Buenas Pr치cticas

| 游댝 Categor칤a | 游댕 Buenas Pr치cticas |
|:---|:---|
| Costes | Autoscale, Auto-pause, controlar sesiones |
| Organizaci칩n | Naming consistente, carpetas tem치ticas |
| C칩digo | Nombres claros, celdas peque침as, no usar `collect()` salvo necesario |
| Seguridad | Roles, no compartir info sensible |
| Almacenamiento | Data Lake estructurado, usar formatos Parquet |


---

# 游 Conclusi칩n

Aplicando estas buenas pr치cticas, lograr치s:
- Trabajar de forma **profesional**.
- **Optimizar costes**.
- **Mantener tu proyecto ordenado** y escalable.

> *"Trabajar bien en Synapse no solo es programar, sino hacerlo de manera eficiente y responsable."* 游

---

# 游녪 춰Felicidades!

Has completado la configuraci칩n b치sica para trabajar con PySpark en Azure Synapse Analytics de forma correcta y profesional.
