# ğŸ“‚ 07 - Configurar Notebooks en Azure Synapse Analytics

---

# ğŸš€ Objetivo

Aprender a crear, configurar y preparar un **Notebook** en **Azure Synapse Studio** para programar con **PySpark**.

---

# ğŸ“š Â¿QuÃ© es un Notebook en Synapse?

- Un **Notebook** es un documento interactivo que contiene:
  - CÃ³digo ejecutable (PySpark, SparkSQL, Scala, C#).
  - Resultados de ejecuciÃ³n.
  - Comentarios en Markdown.
- Permite programar y ver resultados **directamente en la nube**.

> En Synapse, los Notebooks son la forma mÃ¡s rÃ¡pida y visual de trabajar con Spark.

---

# ğŸ”¢ Paso a paso para crear un Notebook

## 1. Entrar a Synapse Studio

- Accede a tu Synapse Workspace.
- Abre el **Synapse Studio** ([https://web.azuresynapse.net/](https://web.azuresynapse.net/)).

## 2. Crear un nuevo Notebook

- En el menÃº izquierdo, haz clic en **Develop**.
- Clic en **+ Notebook**.

## 3. Asignar un Spark Pool al Notebook

- Arriba del Notebook, verÃ¡s la opciÃ³n "**Attach to**".
- Selecciona el Spark Pool que creaste (ej: `sparkpool-demo`).

> ğŸ“Œ **Importante:** Sin Spark Pool, el Notebook no podrÃ¡ ejecutar cÃ³digo PySpark.

## 4. Configurar el lenguaje

- En cada celda, puedes elegir el lenguaje:
  - **PySpark** (Python)
  - **Spark SQL** (SQL)
  - **Scala**
  - **.NET for Apache Spark (C#)**

- Selecciona **PySpark** para programar en Python.


## 5. Primeras pruebas en el Notebook

### Crear una sesiÃ³n

Al escribir tu primer cÃ³digo y darle a "Run", el Spark Pool iniciarÃ¡ una sesiÃ³n.

Ejemplo de cÃ³digo PySpark para probar:

```python
# Crear un DataFrame sencillo
datos = [("Ana", 30), ("Luis", 25), ("Carlos", 35)]
columnas = ["Nombre", "Edad"]

# Crear DataFrame
df = spark.createDataFrame(datos, columnas)

# Mostrar los datos
df.show()
```

### Resultado esperado:

```
+-------+----+
| Nombre|Edad|
+-------+----+
|    Ana|  30|
|   Luis|  25|
| Carlos|  35|
+-------+----+
```

> ğŸ”¸ Si ves este resultado, tu Notebook y Spark Pool estÃ¡n funcionando correctamente.

---

# ğŸ“Š Buenas prÃ¡cticas con Notebooks

- **Pon tÃ­tulos** claros en cada Notebook.
- **Divide** tu cÃ³digo en varias celdas pequeÃ±as.
- **Anota** tus notebooks usando celdas Markdown para explicar procesos.
- **DetÃ©n tu sesiÃ³n** si no estÃ¡s trabajando para ahorrar recursos.


---

# ğŸ› ï¸ Opciones adicionales

- Puedes guardar tu Notebook en el almacenamiento del Workspace.
- Puedes exportarlo como archivo `.ipynb` compatible con Jupyter.


---

# ğŸŒŸ Resultado esperado

- Tienes un Notebook conectado a un Spark Pool listo para trabajar.
- Has ejecutado tu primer cÃ³digo PySpark en la nube.

---

# ğŸ“‚ Siguiente archivo: `08_primer_notebook_synapse.md`
